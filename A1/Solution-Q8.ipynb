{
 "metadata": {
  "name": "",
  "signature": "sha256:f49a641b74b375f812af88f6978d7b2ebc5b4d9033d487dbf70b0f60d5be1486"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_selection import *\n",
      "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specify the location to the data file\n",
      "data_file = \"bank_partial.csv\"\n",
      "\n",
      "# define column names\n",
      "var_names = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"day_of_week\",\n",
      "             \"duration\", \"campaign\", \"pdays\", \"previous\", \"poutcome\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\",\n",
      "             \"euribor3m\", \"nr.employed\", \"y\"]\n",
      "\n",
      "# read from text file, exclude header in the data\n",
      "df_data = pd.read_csv(data_file, sep=\",\", names=var_names, header=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get all the discrete attributes\n",
      "disc_cols = [col for col in df_data.columns if df_data[col].dtype == np.object ]\n",
      "# get all the continous attributes\n",
      "cont_cols = [col for col in df_data.columns if df_data[col].dtype == np.int64 ]\n",
      "\n",
      "print \"discrete: %d\" % len(disc_cols), disc_cols\n",
      "print \"continuous: %d\" % len(cont_cols), cont_cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "discrete: 11 ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
        "continuous: 5 ['age', 'duration', 'campaign', 'pdays', 'previous']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Encode string values to integers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(sklearn classifiers do not take string values as input)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# encode string values to integers\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "# maintain a dict for string to integer mappings for each column\n",
      "label_dict = dict()\n",
      "for col in disc_cols:\n",
      "    le = LabelEncoder()\n",
      "    # map the string values\n",
      "    df_data[col] = le.fit_transform(df_data[col])\n",
      "    # store the mapping in the dict\n",
      "    label_dict[col] = dict()\n",
      "    for cls, label in zip(le.classes_, le.transform(le.classes_)):\n",
      "        label_dict[col][label] = cls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Encode discrete attributes with integer values to factors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" \n",
      "One hot encoding forces sklearn classifiers to treat discrete attributes as factors.\n",
      "\n",
      "\"\"\"\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "# create an instance of OneHotEncoder\n",
      "ohe = OneHotEncoder()\n",
      "# create a new data frame using one hot encoding\n",
      "\n",
      "# extract continuous attributes to the new data frame\n",
      "df_data2 = df_data[cont_cols]\n",
      "\n",
      "# a container used to store names of the new attributes\n",
      "ohe_cols = []\n",
      "\n",
      "# exclude class variable from One Hot encoding\n",
      "disc_cols.remove(\"y\")\n",
      "\n",
      "# encode each discrete attribute\n",
      "for col in disc_cols:\n",
      "    ohe = OneHotEncoder()\n",
      "    encoded = ohe.fit_transform(df_data[[col]]).toarray()\n",
      "    # create names for the new attributes\n",
      "    names = [col+\"=\"+str(i) for i in range(ohe.n_values_)]\n",
      "    ohe_cols.extend(names)\n",
      "    # transform the encoded values to a data frame\n",
      "    df_encoded = pd.DataFrame(encoded, columns=names)\n",
      "    # concatenate the data frame with the larger new data frame\n",
      "    df_data2 = pd.concat([df_data2, df_encoded], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Partition the data set for cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "\n",
      "# partition: train/test = 80/20\n",
      "train_x, test_x, train_y, test_y = train_test_split(df_data2, df_data[\"y\"], test_size=0.2, random_state=123)\n",
      "\n",
      "# convert numpy arrays to data frames\n",
      "df_train_x = pd.DataFrame(train_x, columns=df_data2.columns)\n",
      "df_test_x = pd.DataFrame(test_x, columns=df_data2.columns)\n",
      "df_train_y = pd.DataFrame(train_y, columns=[\"y\"])\n",
      "df_test_y = pd.DataFrame(test_y, columns=[\"y\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Recursive Feature Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.feature_selection import RFECV\n",
      "from sklearn.datasets import make_classification\n",
      "\n",
      "# adjust the shape \n",
      "y = df_train_y[\"y\"].values\n",
      "y.shape = (len(y),)\n",
      "    \n",
      "svc = SVC(kernel=\"linear\")\n",
      "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(y, n_folds=2), scoring=\"f1\")\n",
      "rfecv.fit(df_train_x, y)\n",
      "\n",
      "print \"Number of features selected: %d\" % rfecv.n_features_\n",
      "print \"Selected features:\"\n",
      "rfe_features = []\n",
      "for col, selected in zip(df_data2.columns, rfecv.get_support()):\n",
      "    if selected: \n",
      "        print col\n",
      "        rfe_features.append(col)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now using Decision Tree Classifier\n",
      "\n",
      "from sklearn import tree\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
      "clf = clf.fit(df_train_x[rfe_features], train_y)\n",
      "pred_y = clf.predict(df_test_x[rfe_features])\n",
      "print \"F1 using RFE feauteres: %.4f\" % f1_score(pred_y, test_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}