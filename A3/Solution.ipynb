{
 "metadata": {
  "signature": "sha256:482b30b4962e1aa9ec6ac9255e794b64466edbca6c79241d3dcea17ca5ed8088"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import *\n",
      "from sklearn import metrics, cross_validation\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.preprocessing import normalize\n",
      "import nltk\n",
      "import pandas as pd\n",
      "import gensim\n",
      "import numpy as np\n",
      "from gensim.models import LdaModel, LsiModel\n",
      "from sklearn.cross_validation import StratifiedKFold\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Read CSV file into a pandas dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_data = pd.read_csv(\"amazon_review_texts.csv\", sep=\",\")\n",
      "print df_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          pid helpful  score  \\\n",
        "0  B000GAYQL8     0/0      5   \n",
        "1  B000IBNPDA     0/0      5   \n",
        "2  B000J2HA16     0/0      5   \n",
        "3  B000BDIQPM     0/0      5   \n",
        "4  B000GZTH9E     0/3      4   \n",
        "\n",
        "                                                text category  \n",
        "0  GREAT WATCH AND GREAT LOOK. BIG FACE AND 4 DIF...    watch  \n",
        "1  Bought this as a Christmas gift, my boyfriend ...    watch  \n",
        "2  I love this watch! Its sporty, without looking...    watch  \n",
        "3  Works great,looks nice,dont have to worry abou...    watch  \n",
        "4  I need to change the watch wrist and I havent ...    watch  \n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data types of the columns\n",
      "print df_data.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pid          object\n",
        "helpful      object\n",
        "score       float64\n",
        "text         object\n",
        "category     object\n",
        "dtype: object\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "So the variables are,\n",
      "\n",
      "Continuous: score\n",
      "Discrete: pid, helpful, text, category"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# frequency count for score variable\n",
      "print df_data.score.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5    2070\n",
        "4     773\n",
        "1     595\n",
        "3     303\n",
        "2     259\n",
        "dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract only the text\n",
      "text_list = list(df_data.text)\n",
      "# print len(text_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # create a CountVectorizer instance\n",
      "# vectorizer = CountVectorizer()\n",
      "\n",
      "# # transform the docs into vectors of word frequency\n",
      "# X = vectorizer.fit_transform(text_list)\n",
      "\n",
      "# # cover the dense matrix to a data frame\n",
      "# df_tf = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
      "\n",
      "# # print the data frame\n",
      "# print df_tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "# get a set of stopwords\n",
      "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
      "\n",
      "# create a regex tokenizer that only consider alphabets as token\n",
      "# this also removes numbers\n",
      "tokenizer = nltk.tokenize.RegexpTokenizer(r\"[a-z]+\")\n",
      "\n",
      "# initialize a stemmer\n",
      "stemmer = nltk.stem.PorterStemmer()\n",
      "\n",
      "# initialize a container of token frequencies\n",
      "fdist = nltk.FreqDist()\n",
      "\n",
      "# define a function that preprocess a single document and returns a list of tokens\n",
      "def preprocess(doc):\n",
      "    tokens = []\n",
      "    for token in tokenizer.tokenize(doc.lower()):\n",
      "        if token not in stopwords:\n",
      "            tokens.append(stemmer.stem(token))\n",
      "    return tokens\n",
      "            \n",
      "\n",
      "# preprocess all documents\n",
      "processed = map(preprocess, text_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.07 s, sys: 52.4 ms, total: 4.12 s\n",
        "Wall time: 4.19 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate the token frequency\n",
      "# the FreqDist function takes in a list of tokens and return a dict containg unique tokens and frequency\n",
      "fdist = nltk.FreqDist([token for doc in processed for token in doc])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist.tabulate(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "watch  use  one work time like product great  get would \n",
        "2553 2476 1795 1605 1421 1376 1336 1318 1310 1217 \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Unique tokens: %d\" % fdist.B()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique tokens: 10436\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Vectorize the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_doc = map(\" \".join, processed)\n",
      "# normalization is needed for clustering\n",
      "vectorizer = TfidfVectorizer(stop_words='english')\n",
      "X = vectorizer.fit_transform(processed_doc)\n",
      "print vectorizer\n",
      "print "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of features: %d\" % len(vectorizer.vocabulary_)\n",
      "print len(vectorizer.get_feature_names())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 10275\n",
        "10275\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nmi_sum=0\n",
      "for i in range(0,10):\n",
      "    km = KMeans(n_clusters=4, max_iter=100, random_state=i)\n",
      "    km.fit(X)\n",
      "    nmi = metrics.normalized_mutual_info_score(df_data['category'], km.labels_)\n",
      "    nmi_sum = nmi_sum + nmi\n",
      "    print\"NMI for random state(%d): %0.3f\"% (i,nmi)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NMI for random state(0): 0.397\n",
        "NMI for random state(1): 0.396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(2): 0.416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(3): 0.414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(4): 0.391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(5): 0.392"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(6): 0.414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(7): 0.397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(8): 0.397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(9): 0.414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Average NMI: %0.3f\"% (nmi_sum/10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Average NMI: 0.403\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(min_df=0.01,stop_words='english')\n",
      "X = vectorizer.fit_transform(processed_doc)\n",
      "\n",
      "nmi_sum=0\n",
      "for i in range(0,10):\n",
      "    km = KMeans(n_clusters=4, max_iter=100, random_state=i)\n",
      "    km.fit(X)\n",
      "    nmi = metrics.normalized_mutual_info_score(df_data['category'], km.labels_)\n",
      "    nmi_sum = nmi_sum + nmi\n",
      "    print\"NMI for random state(%d): %0.3f\"% (i,nmi)\n",
      "\n",
      "print \"Average NMI: %0.3f\"% (nmi_sum/10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NMI for random state(0): 0.383\n",
        "NMI for random state(1): 0.486"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(2): 0.484"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(3): 0.488"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(4): 0.416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(5): 0.484"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(6): 0.417"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(7): 0.537"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(8): 0.488"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NMI for random state(9): 0.383"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Average NMI: 0.457\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words='english')\n",
      "X = vectorizer.fit_transform(processed_doc)\n",
      "\n",
      "km = KMeans(n_clusters=4, max_iter=100, random_state=0)\n",
      "km.fit(X)\n",
      "\n",
      "# examine the representative words for each cluster\n",
      "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
      "terms = vectorizer.get_feature_names()\n",
      "for i in range(4):\n",
      "    print(\"Cluster %d:\" % i)\n",
      "    for ind in order_centroids[i, :10]:\n",
      "        print(' %s' % terms[ind])\n",
      "    print\n",
      "    \n",
      "# watch, automotive, electronic, and software"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cluster 0:\n",
        " batteri\n",
        " charg\n",
        " charger\n",
        " power\n",
        " adapt\n",
        " appl\n",
        " canon\n",
        " camera\n",
        " work\n",
        " origin\n",
        "\n",
        "Cluster 1:\n",
        " bed\n",
        " air\n",
        " inflat\n",
        " filter\n",
        " comfort\n",
        " pump\n",
        " sleep\n",
        " mattress\n",
        " deflat\n",
        " airb\n",
        "\n",
        "Cluster 2:\n",
        " use\n",
        " product\n",
        " work\n",
        " great\n",
        " instal\n",
        " good\n",
        " program\n",
        " softwar\n",
        " like\n",
        " time\n",
        "\n",
        "Cluster 3:\n",
        " watch\n",
        " look\n",
        " band\n",
        " time\n",
        " great\n",
        " wear\n",
        " love\n",
        " like\n",
        " nice\n",
        " price\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_vect = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert the vectorized data to a gensim corpus object\n",
      "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
      "# maintain a dictionary for index-word mapping\n",
      "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.iteritems())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build the lda model\n",
      "lda = LdaModel(corpus, num_topics=4,id2word=id2word, passes=10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind=0\n",
      "for item in lda.show_topics():\n",
      "    print \"\\nTopic \",ind\n",
      "    ind=ind+1\n",
      "    for data in item.split('+'):\n",
      "#         print data.split('*')[1]\n",
      "        print data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Topic  0\n",
        "0.020*batteri \n",
        " 0.017*watch \n",
        " 0.013*charg \n",
        " 0.011*charger \n",
        " 0.010*work \n",
        " 0.010*time \n",
        " 0.009*use \n",
        " 0.009*great \n",
        " 0.008*year \n",
        " 0.008*replac\n",
        "\n",
        "Topic  1\n",
        "0.044*watch \n",
        " 0.017*look \n",
        " 0.017*great \n",
        " 0.015*love \n",
        " 0.012*price \n",
        " 0.011*band \n",
        " 0.010*good \n",
        " 0.010*nice \n",
        " 0.010*product \n",
        " 0.010*bought\n",
        "\n",
        "Topic  2\n",
        "0.020*air \n",
        " 0.018*bed \n",
        " 0.016*filter \n",
        " 0.014*use \n",
        " 0.012*instal \n",
        " 0.011*power \n",
        " 0.011*inflat \n",
        " 0.011*easi \n",
        " 0.010*adapt \n",
        " 0.010*work\n",
        "\n",
        "Topic  3\n",
        "0.013*use \n",
        " 0.010*softwar \n",
        " 0.010*program \n",
        " 0.009*game \n",
        " 0.009*product \n",
        " 0.009*work \n",
        " 0.007*comput \n",
        " 0.006*like \n",
        " 0.006*version \n",
        " 0.006*player\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "# 10-fold cross validation\n",
      "skf = StratifiedKFold(df_data[\"score\"], n_folds=10)\n",
      "\n",
      "fold = 0\n",
      "\n",
      "f1 = []\n",
      "features = []\n",
      "\n",
      "for train_index, test_index in skf:\n",
      "    fold += 1\n",
      "    print \"Fold %d\" % fold\n",
      "    # partition\n",
      "    train_x, test_x = df_data[\"text\"].iloc[train_index], df_data[\"text\"].iloc[test_index]\n",
      "    train_y, test_y = df_data[\"score\"].iloc[train_index], df_data[\"score\"].iloc[test_index]\n",
      "    # vectorize\n",
      "    #vectorizer = TfidfVectorizer(tokenizer=tokenizer, max_df=0.8, stop_words='english')\n",
      "    vectorizer = TfidfVectorizer(min_df=2, stop_words='english')\n",
      "    X = vectorizer.fit_transform(train_x)\n",
      "    X_test = vectorizer.transform(test_x)\n",
      "    # train model\n",
      "    clf = SGDClassifier(random_state=fold)\n",
      "    clf.fit(X, train_y)\n",
      "    # predict\n",
      "    pred = clf.predict(X_test)\n",
      "    # classification results\n",
      "    for line in metrics.classification_report(test_y, pred).split(\"\\n\"):\n",
      "        print line\n",
      "    f1.append(metrics.f1_score(test_y, pred))\n",
      "    features.append(len(vectorizer.vocabulary_))\n",
      "print \"Average F1: %.2f\" % np.mean(f1)\n",
      "print \"Average Features: %.2f\" % np.mean(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold 1\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.56      0.45      0.50        60\n",
        "        2.0       0.21      0.12      0.15        26\n",
        "        3.0       0.23      0.10      0.14        31\n",
        "        4.0       0.30      0.15      0.20        78\n",
        "        5.0       0.64      0.89      0.75       207\n",
        "\n",
        "avg / total       0.51      0.57      0.52       402\n",
        "\n",
        "Fold 2\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.74      0.47      0.57        60\n",
        "        2.0       0.36      0.15      0.22        26\n",
        "        3.0       0.38      0.19      0.26        31\n",
        "        4.0       0.30      0.19      0.23        78\n",
        "        5.0       0.64      0.89      0.74       207\n",
        "\n",
        "avg / total       0.55      0.59      0.55       402\n",
        "\n",
        "Fold 3\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.56      0.55      0.55        60\n",
        "        2.0       0.20      0.12      0.15        26\n",
        "        3.0       0.12      0.06      0.09        31\n",
        "        4.0       0.28      0.26      0.27        78\n",
        "        5.0       0.65      0.75      0.70       207\n",
        "\n",
        "avg / total       0.49      0.53      0.51       402\n",
        "\n",
        "Fold 4\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.52      0.70      0.60        60\n",
        "        2.0       0.10      0.04      0.06        26\n",
        "        3.0       0.05      0.03      0.04        30\n",
        "        4.0       0.28      0.19      0.23        77\n",
        "        5.0       0.64      0.72      0.68       207\n",
        "\n",
        "avg / total       0.47      0.52      0.49       400\n",
        "\n",
        "Fold 5\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.51      0.77      0.61        60\n",
        "        2.0       0.12      0.08      0.10        26\n",
        "        3.0       0.11      0.07      0.08        30\n",
        "        4.0       0.30      0.18      0.23        77\n",
        "        5.0       0.70      0.78      0.74       207\n",
        "\n",
        "avg / total       0.51      0.56      0.53       400\n",
        "\n",
        "Fold 6\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.68      0.75      0.71        59\n",
        "        2.0       0.50      0.15      0.24        26\n",
        "        3.0       0.50      0.17      0.25        30\n",
        "        4.0       0.42      0.36      0.39        77\n",
        "        5.0       0.71      0.86      0.77       207\n",
        "\n",
        "avg / total       0.62      0.65      0.62       399\n",
        "\n",
        "Fold 7\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.64      0.63      0.63        59\n",
        "        2.0       0.30      0.12      0.17        26\n",
        "        3.0       0.80      0.27      0.40        30\n",
        "        4.0       0.44      0.55      0.49        77\n",
        "        5.0       0.72      0.78      0.75       207\n",
        "\n",
        "avg / total       0.63      0.63      0.62       399\n",
        "\n",
        "Fold 8\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.69      0.61      0.65        59\n",
        "        2.0       0.43      0.12      0.18        26\n",
        "        3.0       0.88      0.23      0.37        30\n",
        "        4.0       0.38      0.22      0.28        77\n",
        "        5.0       0.62      0.86      0.72       207\n",
        "\n",
        "avg / total       0.59      0.61      0.57       399\n",
        "\n",
        "Fold 9\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.64      0.61      0.63        59\n",
        "        2.0       0.83      0.38      0.53        26\n",
        "        3.0       0.44      0.23      0.30        30\n",
        "        4.0       0.58      0.32      0.42        77\n",
        "        5.0       0.70      0.92      0.79       207\n",
        "\n",
        "avg / total       0.66      0.67      0.64       399\n",
        "\n",
        "Fold 10\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "        1.0       0.76      0.44      0.56        59\n",
        "        2.0       0.67      0.24      0.35        25\n",
        "        3.0       0.73      0.27      0.39        30\n",
        "        4.0       0.61      0.22      0.32        77\n",
        "        5.0       0.61      0.94      0.74       207\n",
        "\n",
        "avg / total       0.65      0.63      0.58       398\n",
        "\n",
        "Average F1: 0.56\n",
        "Average Features: 7821.90\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_data2 = df_data.copy()\n",
      "df_data2.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>pid</th>\n",
        "      <th>helpful</th>\n",
        "      <th>score</th>\n",
        "      <th>text</th>\n",
        "      <th>category</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> B000GAYQL8</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> GREAT WATCH AND GREAT LOOK. BIG FACE AND 4 DIF...</td>\n",
        "      <td> watch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> B000IBNPDA</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> Bought this as a Christmas gift, my boyfriend ...</td>\n",
        "      <td> watch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> B000J2HA16</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> I love this watch! Its sporty, without looking...</td>\n",
        "      <td> watch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> B000BDIQPM</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> Works great,looks nice,dont have to worry abou...</td>\n",
        "      <td> watch</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> B000GZTH9E</td>\n",
        "      <td> 0/3</td>\n",
        "      <td> 4</td>\n",
        "      <td> I need to change the watch wrist and I havent ...</td>\n",
        "      <td> watch</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "          pid helpful  score  \\\n",
        "0  B000GAYQL8     0/0      5   \n",
        "1  B000IBNPDA     0/0      5   \n",
        "2  B000J2HA16     0/0      5   \n",
        "3  B000BDIQPM     0/0      5   \n",
        "4  B000GZTH9E     0/3      4   \n",
        "\n",
        "                                                text category  \n",
        "0  GREAT WATCH AND GREAT LOOK. BIG FACE AND 4 DIF...    watch  \n",
        "1  Bought this as a Christmas gift, my boyfriend ...    watch  \n",
        "2  I love this watch! Its sporty, without looking...    watch  \n",
        "3  Works great,looks nice,dont have to worry abou...    watch  \n",
        "4  I need to change the watch wrist and I havent ...    watch  "
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_data2['satisfaction'] = map(lambda x: 1 if x==5 else 0, df_data2.score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_data2.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>pid</th>\n",
        "      <th>helpful</th>\n",
        "      <th>score</th>\n",
        "      <th>text</th>\n",
        "      <th>category</th>\n",
        "      <th>satisfaction</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> B000GAYQL8</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> GREAT WATCH AND GREAT LOOK. BIG FACE AND 4 DIF...</td>\n",
        "      <td> watch</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> B000IBNPDA</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> Bought this as a Christmas gift, my boyfriend ...</td>\n",
        "      <td> watch</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> B000J2HA16</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> I love this watch! Its sporty, without looking...</td>\n",
        "      <td> watch</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> B000BDIQPM</td>\n",
        "      <td> 0/0</td>\n",
        "      <td> 5</td>\n",
        "      <td> Works great,looks nice,dont have to worry abou...</td>\n",
        "      <td> watch</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> B000GZTH9E</td>\n",
        "      <td> 0/3</td>\n",
        "      <td> 4</td>\n",
        "      <td> I need to change the watch wrist and I havent ...</td>\n",
        "      <td> watch</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "          pid helpful  score  \\\n",
        "0  B000GAYQL8     0/0      5   \n",
        "1  B000IBNPDA     0/0      5   \n",
        "2  B000J2HA16     0/0      5   \n",
        "3  B000BDIQPM     0/0      5   \n",
        "4  B000GZTH9E     0/3      4   \n",
        "\n",
        "                                                text category  satisfaction  \n",
        "0  GREAT WATCH AND GREAT LOOK. BIG FACE AND 4 DIF...    watch             1  \n",
        "1  Bought this as a Christmas gift, my boyfriend ...    watch             1  \n",
        "2  I love this watch! Its sporty, without looking...    watch             1  \n",
        "3  Works great,looks nice,dont have to worry abou...    watch             1  \n",
        "4  I need to change the watch wrist and I havent ...    watch             0  "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "# 10-fold cross validation\n",
      "skf = StratifiedKFold(df_data2[\"satisfaction\"], n_folds=10)\n",
      "\n",
      "fold = 0\n",
      "\n",
      "f1 = []\n",
      "features = []\n",
      "\n",
      "for train_index, test_index in skf:\n",
      "    fold += 1\n",
      "    print \"Fold %d\" % fold\n",
      "    # partition\n",
      "    train_x, test_x = df_data2[\"text\"].iloc[train_index], df_data2[\"text\"].iloc[test_index]\n",
      "    train_y, test_y = df_data2[\"satisfaction\"].iloc[train_index], df_data2[\"satisfaction\"].iloc[test_index]\n",
      "    # vectorize\n",
      "    #vectorizer = TfidfVectorizer(tokenizer=tokenizer, max_df=0.8, stop_words='english')\n",
      "    vectorizer = TfidfVectorizer(min_df=2, stop_words='english')\n",
      "    X = vectorizer.fit_transform(train_x)\n",
      "    X_test = vectorizer.transform(test_x)\n",
      "    # train model\n",
      "    clf = SGDClassifier(random_state=fold)\n",
      "    clf.fit(X, train_y)\n",
      "    # predict\n",
      "    pred = clf.predict(X_test)\n",
      "    # classification results\n",
      "    for line in metrics.classification_report(test_y, pred).split(\"\\n\"):\n",
      "        print line\n",
      "    f1.append(metrics.f1_score(test_y, pred))\n",
      "    features.append(len(vectorizer.vocabulary_))\n",
      "print \"Average F1: %.2f\" % np.mean(f1)\n",
      "print \"Average Features: %.2f\" % np.mean(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold 1\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.74      0.66      0.70       193\n",
        "          1       0.71      0.79      0.75       207\n",
        "\n",
        "avg / total       0.73      0.72      0.72       400\n",
        "\n",
        "Fold 2\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.81      0.46      0.59       193\n",
        "          1       0.64      0.90      0.75       207\n",
        "\n",
        "avg / total       0.72      0.69      0.67       400\n",
        "\n",
        "Fold 3\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.58      0.69      0.63       193\n",
        "          1       0.65      0.54      0.59       207\n",
        "\n",
        "avg / total       0.62      0.61      0.61       400\n",
        "\n",
        "Fold 4\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.60      0.71      0.65       193\n",
        "          1       0.67      0.55      0.60       207\n",
        "\n",
        "avg / total       0.63      0.63      0.63       400\n",
        "\n",
        "Fold 5\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.69      0.79      0.74       193\n",
        "          1       0.77      0.66      0.71       207\n",
        "\n",
        "avg / total       0.73      0.72      0.72       400\n",
        "\n",
        "Fold 6\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.79      0.69      0.74       193\n",
        "          1       0.74      0.83      0.78       207\n",
        "\n",
        "avg / total       0.77      0.76      0.76       400\n",
        "\n",
        "Fold 7\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.68      0.81      0.74       193\n",
        "          1       0.78      0.64      0.70       207\n",
        "\n",
        "avg / total       0.73      0.72      0.72       400\n",
        "\n",
        "Fold 8\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.71      0.51      0.59       193\n",
        "          1       0.64      0.80      0.71       207\n",
        "\n",
        "avg / total       0.67      0.66      0.65       400\n",
        "\n",
        "Fold 9\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.81      0.67      0.74       193\n",
        "          1       0.74      0.86      0.79       207\n",
        "\n",
        "avg / total       0.77      0.77      0.77       400\n",
        "\n",
        "Fold 10\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.83      0.40      0.54       193\n",
        "          1       0.62      0.92      0.74       207\n",
        "\n",
        "avg / total       0.72      0.67      0.65       400\n",
        "\n",
        "Average F1: 0.71\n",
        "Average Features: 7823.00\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read the lexicon\n",
      "lexicon = dict()\n",
      "\n",
      "# read postive words\n",
      "with open(\"negative-words.txt\", \"r\") as in_file:\n",
      "    for line in in_file.readlines():\n",
      "        if not line.startswith(\";\") and line != \"\\n\":\n",
      "            lexicon[line.strip()] = -1\n",
      "\n",
      "# read negative words\n",
      "with open(\"positive-words.txt\", \"r\") as in_file:\n",
      "    for line in in_file.readlines():\n",
      "        if not line.startswith(\";\") and line != \"\\n\":\n",
      "            lexicon[line.strip()] = 1\n",
      "\n",
      "# print the top 5 entries\n",
      "for i, (k, v) in enumerate(lexicon.items()):\n",
      "    print k, v\n",
      "    if i > 4: break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cussed -1\n",
        "foul -1\n",
        "mirage -1\n",
        "aggression -1\n",
        "chatter -1\n",
        "scold -1\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = nltk.tokenize.RegexpTokenizer(\"[a-z]+\")\n",
      "# print tokenizer.tokenize(\"hello 12 world.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define a function that uses sentiment word voting to classify sentiment\n",
      "def lexicon_classify(text):\n",
      "    score = 0\n",
      "    for token in tokenizer.tokenize(text):\n",
      "        score += lexicon.get(token, 0)\n",
      "    if score > 0: return 1\n",
      "    elif score <0: return 0\n",
      "    else: return 0\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_data2[\"satisfaction\"].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "1    2070\n",
        "0    1930\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# classify using the lexicon\n",
      "df_data2[\"lex_satisfaction\"] = df_data2[\"text\"].apply(lexicon_classify)\n",
      "df_data2[\"lex_satisfaction\"].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "1    2838\n",
        "0    1162\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "# 10-fold cross validation\n",
      "skf = StratifiedKFold(df_data2[\"lex_satisfaction\"], n_folds=10)\n",
      "\n",
      "fold = 0\n",
      "\n",
      "f1 = []\n",
      "features = []\n",
      "\n",
      "for train_index, test_index in skf:\n",
      "    fold += 1\n",
      "    print \"Fold %d\" % fold\n",
      "    # partition\n",
      "    train_x, test_x = df_data2[\"text\"].iloc[train_index], df_data2[\"text\"].iloc[test_index]\n",
      "    train_y, test_y = df_data2[\"lex_satisfaction\"].iloc[train_index], df_data2[\"lex_satisfaction\"].iloc[test_index]\n",
      "    # vectorize\n",
      "    #vectorizer = TfidfVectorizer(tokenizer=tokenizer, max_df=0.8, stop_words='english')\n",
      "    vectorizer = TfidfVectorizer(min_df=2, stop_words='english')\n",
      "    X = vectorizer.fit_transform(train_x)\n",
      "    X_test = vectorizer.transform(test_x)\n",
      "    # train model\n",
      "    clf = SGDClassifier(random_state=fold)\n",
      "    clf.fit(X, train_y)\n",
      "    # predict\n",
      "    pred = clf.predict(X_test)\n",
      "    # classification results\n",
      "    for line in metrics.classification_report(test_y, pred).split(\"\\n\"):\n",
      "        print line\n",
      "    f1.append(metrics.f1_score(test_y, pred))\n",
      "    features.append(len(vectorizer.vocabulary_))\n",
      "print \"Average F1: %.2f\" % np.mean(f1)\n",
      "print \"Average Features: %.2f\" % np.mean(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold 1\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.75      0.53      0.62       117\n",
        "          1       0.83      0.93      0.87       284\n",
        "\n",
        "avg / total       0.80      0.81      0.80       401\n",
        "\n",
        "Fold 2\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.82      0.54      0.65       117\n",
        "          1       0.83      0.95      0.89       284\n",
        "\n",
        "avg / total       0.83      0.83      0.82       401\n",
        "\n",
        "Fold 3\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.62      0.66      0.64       116\n",
        "          1       0.86      0.83      0.84       284\n",
        "\n",
        "avg / total       0.79      0.78      0.78       400\n",
        "\n",
        "Fold 4\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.63      0.57      0.60       116\n",
        "          1       0.83      0.87      0.85       284\n",
        "\n",
        "avg / total       0.77      0.78      0.78       400\n",
        "\n",
        "Fold 5\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.64      0.56      0.60       116\n",
        "          1       0.83      0.87      0.85       284\n",
        "\n",
        "avg / total       0.78      0.78      0.78       400\n",
        "\n",
        "Fold 6\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.81      0.69      0.74       116\n",
        "          1       0.88      0.93      0.91       284\n",
        "\n",
        "avg / total       0.86      0.86      0.86       400\n",
        "\n",
        "Fold 7\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.85      0.67      0.75       116\n",
        "          1       0.88      0.95      0.91       284\n",
        "\n",
        "avg / total       0.87      0.87      0.87       400\n",
        "\n",
        "Fold 8\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.72      0.66      0.68       116\n",
        "          1       0.86      0.89      0.88       284\n",
        "\n",
        "avg / total       0.82      0.82      0.82       400\n",
        "\n",
        "Fold 9\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.69      0.62      0.65       116\n",
        "          1       0.85      0.88      0.87       283\n",
        "\n",
        "avg / total       0.80      0.81      0.80       399\n",
        "\n",
        "Fold 10\n",
        "             precision    recall  f1-score   support"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "          0       0.77      0.63      0.69       116\n",
        "          1       0.86      0.92      0.89       283\n",
        "\n",
        "avg / total       0.83      0.84      0.83       399\n",
        "\n",
        "Average F1: 0.88\n",
        "Average Features: 7826.70\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}